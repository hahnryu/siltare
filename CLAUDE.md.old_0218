# CLAUDE.md - Siltare (ì‹¤íƒ€ë˜)

> Last updated: 2026-02-18
> Version: 0.1.0 (MVP for Hashed Vibe Labs submission)

## Glossary

- **MVP** (Minimum Viable Product): Demo scope for Hashed submission.
- **SSE** (Server-Sent Events): Server-to-client one-way streaming. Used to send AI responses character by character.
- **i18n** (Internationalization): Multi-language support structure.
- **KST** (Korea Standard Time): UTC+9.

## Priority Legend

- **MUST**: Required. Product breaks if violated.
- **SHOULD**: Strongly recommended. Follow unless there is a specific reason not to.
- **MAY**: Optional. Nice to have if time permits.

## Project Overview

Siltare is an AI life-interview web app.
Send a link, and AI asks about and records a person's life story.

Tagline: "ê·¸ ë¶„ì´ ì•„ì§ ê³ì— ê³„ì‹¤ ë•Œ." (While they are still with you.)
URLs: iyagi.siltare.app (app) / siltare.app (landing)

## Core Flow

1. Requester selects relationship + enters questions at /request -> link generated
2. Interviewee opens /i/[id] link -> consent screen
3. AI starts conversation at /interview/[id] (GPT-4o via SSE streaming)
4. Voice input supported (MediaRecorder -> Whisper API)
5. After completion: transcript + AI summary + chapters at /archive

## Two Modes

- **invite**: Someone wants to hear another person's story (child->parent, student->mentor)
- **self**: Record your own story

## Tech Stack

- Next.js 14 (App Router)
- TypeScript
- Tailwind CSS
- OpenAI API (GPT-4o: conversation/summary, Whisper: speech-to-text)
- Vercel (deployment)
- Data storage: Local JSON files (/data/interviews/) for MVP

## Design System

- Background: #FAF6F0 (warm cream)
- Primary text: #2C2418 (dark bark)
- Accent: #C4956A (warm amber)
- Secondary: #8B7355 (muted brown)
- Muted: #9E9585 (stone gray)
- Card: #FFFDF9 (warm white)
- Border: #E8E0D4 (mist)
- Headline font: 'Noto Serif KR', serif
- Body font: 'Noto Sans KR', sans-serif
- English serif: 'Cormorant Garamond', serif
- Border radius: 6px (buttons), 12px (cards)
- Tone: High-end stationery. Not a tech startup. Warm and restrained.

## Architecture: 3-Layer Rule

This project has three layers. MUST NOT mix them when adding features.

### 1. Pages (app/)
Screen-level units. Each corresponds to a URL route.
- Pages import from components/ and lib/
- Pages MUST NOT import from other pages
- New screens go under app/ as new folders

### 2. Components (components/)
Reusable UI pieces shared across pages.
- May have local state (useState)
- May import types from lib/
- May import other components
- MUST NOT call APIs directly (receive callbacks via props)

### 3. Lib (lib/)
Business logic. Everything that is not UI.
- prompts, types, store, questions, i18n
- No React imports. Pure TypeScript.
- Usable on both server and client

### Rules
- New page: Create folder under app/. Reuse existing components.
- New UI piece: Create file in components/. Single responsibility.
- New logic: Create file in lib/. No UI dependencies.
- Page-specific components still go in components/ (prevent page files from growing large).

## File Structure

```
siltare/
â”œâ”€â”€ CLAUDE.md
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ layout.tsx                  # Global layout
â”‚   â”œâ”€â”€ page.tsx                    # App landing
â”‚   â”‚
â”‚   â”‚  -- Request Flow --
â”‚   â”œâ”€â”€ request/page.tsx            # Invite request (4-step form)
â”‚   â”œâ”€â”€ self/page.tsx               # Self-mode start
â”‚   â”‚
â”‚   â”‚  -- Interview Flow --
â”‚   â”œâ”€â”€ i/[id]/page.tsx             # Interviewee landing (consent)
â”‚   â”œâ”€â”€ interview/[id]/page.tsx     # AI conversation
â”‚   â”œâ”€â”€ interview/[id]/complete/page.tsx  # Completion screen
â”‚   â”‚
â”‚   â”‚  -- Result Flow --
â”‚   â”œâ”€â”€ archive/[id]/page.tsx       # Result archive (summary+chapters+audio)
â”‚   â”œâ”€â”€ edit/[id]/page.tsx          # [FUTURE] Transcript editing
â”‚   â”œâ”€â”€ book/[id]/page.tsx          # Book ordering
â”‚   â”‚
â”‚   â”‚  -- Admin --
â”‚   â”œâ”€â”€ dashboard/page.tsx          # Admin dashboard (owner only)
â”‚   â”‚
â”‚   â”‚  -- API --
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ create-interview/route.ts
â”‚       â”œâ”€â”€ chat/route.ts           # GPT-4o SSE streaming
â”‚       â”œâ”€â”€ transcribe/route.ts     # Whisper speech-to-text
â”‚       â””â”€â”€ complete/route.ts       # Completion (summary + entity extraction)
â”‚
â”œâ”€â”€ components/
â”‚   â”‚  -- Common --
â”‚   â”œâ”€â”€ Header.tsx                  # Siltare logo header
â”‚   â”œâ”€â”€ Footer.tsx                  # [FUTURE] Common footer
â”‚   â”‚
â”‚   â”‚  -- Interview --
â”‚   â”œâ”€â”€ ChatMessage.tsx             # AI/user message bubbles
â”‚   â”œâ”€â”€ MicButton.tsx               # Mic recording (MediaRecorder + Whisper)
â”‚   â”œâ”€â”€ AudioPlayer.tsx             # [FUTURE] Audio playback (archive, edit)
â”‚   â”‚
â”‚   â”‚  -- Forms --
â”‚   â”œâ”€â”€ RelationshipSelector.tsx    # Relationship selection cards
â”‚   â”œâ”€â”€ PackageSelector.tsx         # [FUTURE] Book package selection
â”‚   â”‚
â”‚   â”‚  -- Dashboard --
â”‚   â”œâ”€â”€ MetricCard.tsx              # [FUTURE] Metric card
â”‚   â””â”€â”€ InterviewTable.tsx          # [FUTURE] Interview list table
â”‚
â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ prompts.ts                  # System prompt (CORE. Modify with extreme care)
â”‚   â”œâ”€â”€ types.ts                    # Interview, Message, EntityData
â”‚   â”œâ”€â”€ store.ts                    # JSON file storage (MVP)
â”‚   â”œâ”€â”€ questions.ts                # Recommended questions by relationship
â”‚   â”œâ”€â”€ i18n.ts                     # [FUTURE] Internationalization
â”‚   â””â”€â”€ utils.ts                    # [FUTURE] Common utilities
â”‚
â””â”€â”€ data/interviews/                # MVP data directory
```

### [FUTURE] Marker
[FUTURE] means not built now, but the structural slot is reserved.
When adding later, just create the file without changing existing structure.

## Data Model Evolution

Current MVP uses a minimal Interview model.
Below shows future expansion direction. MUST NOT write code that blocks these expansions.

### Current (MVP)
```
Interview (1 record = 1 conversation, stored as JSON file)
â”œâ”€â”€ id, mode, status
â”œâ”€â”€ requester (name, email, relationship)
â”œâ”€â”€ interviewee (name)
â”œâ”€â”€ messages[] (full conversation)
â””â”€â”€ summary, entities
```

### Future Expansion
```
User
â”œâ”€â”€ id, name, email, role
â”œâ”€â”€ interviews[] (participated interviews)
â””â”€â”€ settings (theme, locale, notifications)

Interview (1 record = one life-story project)
â”œâ”€â”€ id, mode, status, visibility, locale
â”œâ”€â”€ participants[] (User refs, roles: requester/interviewee/editor/viewer)
â”‚
â”œâ”€â”€ sessions[] (multiple conversations over days)
â”‚   â”œâ”€â”€ Session 1 (2026.02.15, 32min)
â”‚   â”‚   â”œâ”€â”€ messages[]
â”‚   â”‚   â””â”€â”€ audioChunks[]
â”‚   â””â”€â”€ Session 2 (2026.02.18, 25min)
â”‚       â”œâ”€â”€ messages[]
â”‚       â””â”€â”€ audioChunks[]
â”‚
â”œâ”€â”€ transcript (original, immutable)
â”œâ”€â”€ editedTranscript (edited version, preserves edit history)
â”‚   â””â”€â”€ edits[] { from, to, editedBy, timestamp }
â”‚
â”œâ”€â”€ chapters[] (AI-generated + user-editable)
â”œâ”€â”€ summary, entities
â”‚
â”œâ”€â”€ visibility: 'private' | 'family' | 'public' | 'anonymized' | 'corpus'
â”œâ”€â”€ book { package, status, coverStyle, deliveryInfo }
â”‚
â””â”€â”€ metadata
    â”œâ”€â”€ totalDuration, completionRate
    â””â”€â”€ locale (e.g., 'ko', 'en', 'ja')
```

### MVP Principles
- Interview.messages[] will later become sessions[].messages[].
  For now, keep flat. MUST access messages only through store.ts functions.
- Original transcript and editedTranscript are separate.
  MUST NOT overwrite transcript field directly.
- Visibility does not exist yet. Add TODO comments in API routes: "TODO: add auth check here".
- Locale does not exist yet. Keep all user-facing strings in a structure that allows future extraction (see i18n section).

### Voice Recording Architecture

**Current (MVP): Per-turn recording, press-and-hold**
- User presses and holds mic button to record
- Release to stop + auto-send (Telegram/WeChat pattern)
- One gesture completes the action: "Press, speak, release."
- Per turn: 10s to 1min short audio
- Uploads full blob to /api/transcribe
- Safe at this size (hundreds of KB)
- Implementation: onMouseDown/onTouchStart -> startRecording, onMouseUp/onTouchEnd -> stopRecording
- Visual feedback during recording: red + pulse animation + "ë“£ê³  ìˆìŠµë‹ˆë‹¤..." text

**Future (Layer 1-2): Continuous recording or auto-send**
- MUST switch to 10-15 second chunk uploads
- Flow: MediaRecorder -> 10s blob -> immediate server upload -> Whisper -> DB append
- Store original audio chunks in S3
- Append transcription results to DB
- Previous chunks preserved if connection drops
- Session recovery: reconnect with same interview ID to continue

**Future (Layer 3+): Real-time voice conversation**
- OpenAI Realtime API (WebRTC-based)
- Simultaneous voice I/O + transcription
- Too network-dependent for MVP

**Code guidelines:**
- MUST keep MicButton's onTranscription callback interface stable
- /api/transcribe keeps single audio blob interface
- Add /api/transcribe-chunk as new endpoint for chunk mode

## Internationalization (i18n) Structure

### Current (MVP): Korean only
- All user-facing text is Korean, hardcoded in components
- CLAUDE.md and code comments are in English
- lib/prompts.ts system prompt is in Korean (product requirement)

### Future-proofing rules (SHOULD follow now)
1. User-facing strings SHOULD be written as named constants, not inline literals
2. When i18n is added (Layer 4), create lib/i18n.ts with ko/en/ja locales
3. System prompt (lib/prompts.ts) will need locale-specific versions
4. UI language and interview language may differ

## Feature Layer Roadmap

### Layer 0: Now (Hashed submission)
- Static mockups + AI conversation working 2-3 turns
- No auth, JSON file storage
- Single session (one-shot)

### Layer 1: Parents' Day MVP (Apr-May)
- Payment (Toss Payments)
- Multi-session support ("Continue next time")
- Email result delivery
- KakaoTalk sharing

### Layer 2: Editing + Sharing (Jun-Jul)
- Transcript typo correction UI
- AI-highlighted typo candidates (dialect/proper noun detection)
- Family sharing link (password protected)
- Requester dashboard: progress, editing, book ordering

### Layer 3: Users + Permissions (Aug-Sep)
- Authentication (Kakao Login)
- Role-based dashboards (requester / interviewee / admin)
- Interviewee can view own records
- Completion percentage ("Father's story, 68% complete")

### Layer 4: Theme + i18n (TBD)
- Dark mode (CSS variables already in :root)
- English, Japanese UI
- Multi-language interviews (prompt language switching)

### Layer 5: Publication + Corpus (TBD)
- Public sharing option
- Anonymized publication (auto-replace names/places)
- Ontology corpus contribution (public interest, separate consent)
- Collective memory research dataset

## Dashboard Distinction

### /dashboard (Admin only, owner's view)
- Total interviews, revenue, conversion rate
- Recent interview list
- Data accumulation status
- Access: Admin auth (Layer 3). For now, accessible by URL only.

### /my/[id] (User-facing, FUTURE)
- Requester's view: "Father's Story" progress
- Session list (1st, 2nd, 3rd...)
- Transcript viewing + typo correction
- Book order status
- Family sharing management

## Coding Rules

### MUST
- Never use em-dash. Nowhere in code, copy, or comments.
- Korean UI. All user-facing text MUST be in Korean (for now).
- Mobile-first. max-width: 520px baseline.
- Elderly users: body text >= 16px, buttons >= 56px height, mic button 72px.
- AI conversation MUST use SSE streaming (character-by-character delivery).
- Access data ONLY through store.ts. No direct JSON file read/write elsewhere.

### SHOULD
- emoji in UI: use ğŸ§µ as logo only.
- lib/ code (especially prompts.ts) is validated core logic. Modify with care.
- New components go in components/, new logic in lib/. Maintain 3-layer rule.
- Leave TODO comments in API routes: "TODO: add auth check here".
- User-facing strings SHOULD be named constants (for future i18n extraction).

### MAY
- Prepare dark mode CSS variables (do not implement yet).
- Add animations and transitions.

## Boundaries: Do NOT

Things Claude Code MUST NEVER do in this project:
- Do NOT modify system prompt content in lib/prompts.ts (style/format fixes excepted).
- Do NOT change business logic in existing API routes. Only fix import paths.
- Do NOT change existing dependency versions in package.json. Only add new packages.
- Do NOT create code that deletes user data (data/interviews/).
- Do NOT hardcode OpenAI API keys. Always use environment variables.
- Do NOT add auth/login features in MVP. That is Layer 3 work.

## Error Handling Guide

### API call failures
- /api/chat failure: Show "ì ì‹œ ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”." Auto-retry once.
- /api/transcribe failure: Show "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”." Prompt text input.
- /api/create-interview failure: Show "ë§í¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

### Build errors
- Import path errors: Verify @/lib/..., @/components/... format.
- Type errors: Check against lib/types.ts interfaces. Add missing fields, do not arbitrarily change types.
- Unknown errors: Revert changes, go back one step. Change only one thing at a time.

## Core Principles (MUST)

These define the product's essence. Never violate during feature additions or refactoring.

1. Elderly users are the primary audience. Large text, large buttons, no complex UI.
2. No signup required. Interviewee just opens a link.
3. Requester only provides email to receive results.
4. AI conversation MUST stream via SSE. Character-by-character creates conversation feel.
5. AI turn is max 3 sentences. Usually 1-2.
6. First question must not be generic. Start from what the child asked about.
7. Mic button must be large and centered. Complex typing UI will make parents give up.
8. Never use the word "ì¸í„°ë·°" (interview). Use "ì´ì•¼ê¸°" (story) or "ëŒ€í™”" (conversation).
9. Do not reveal AI identity during conversation. Mention only on info screens.
10. Product essence: A tool that asks the questions you never could, while your parents are still alive.

## Test Checklist

- [ ] Whisper speech recognition accuracy with 70+ year old Korean speakers
- [ ] AI first question starts from the context the child entered
- [ ] AI turn is 3 sentences or fewer
- [ ] Mic button is 72px or larger
- [ ] All body text is 16px or larger
- [ ] SSE streaming delivers character by character
- [ ] Session saves when user taps "ì˜¤ëŠ˜ì€ ì—¬ê¸°ê¹Œì§€"
- [ ] Full flow click test on mobile

## API Spec

### POST /api/create-interview
```
Input: {
  mode: 'invite' | 'self',
  requester?: { name: string, email: string, relationship: string },
  interviewee: { name: string, ageGroup?: string },
  context: string[],
  context2?: string
}
Output: { id: string, link: string }
```
Creates interview with nanoid, saves as JSON file, returns link.

### GET /api/create-interview?id={id}
```
Output: Full Interview object
```
Retrieves interview data by ID. Used by /i/[id] page.

### POST /api/chat
```
Input: { interviewId: string, message: string }
Output: SSE streaming (text/event-stream)
```
Loads interview -> generateSystemPrompt() -> GPT-4o streaming -> saves messages.

### POST /api/transcribe
```
Input: FormData (audio: Blob)
Output: { text: string }
```
Whisper API speech-to-text transcription.

### POST /api/complete
```
Input: { interviewId: string }
Output: { transcript: string, summary: string, entities: EntityData }
```
Combines all messages into transcript, GPT-4o generates 3-line summary + entity extraction.

## User-Facing Copy (Korean)

All user-facing text is Korean. These are the canonical strings.
When i18n is added, these become the 'ko' locale values.

### v0 Mockup References
- / (landing): https://v0-siltare-landing-page.vercel.app/
- /request: https://v0-siltare-life-interview.vercel.app/
- /i/[id]: https://v0-interviewee-landing-page.vercel.app/
- /interview: https://v0-ai-voice-interview-psi.vercel.app/
- /archive: https://v0-interview-archive-page.vercel.app/
- /book: https://v0-book-order-page.vercel.app/
- /dashboard: https://v0-siltare-admin-dashboard.vercel.app/

### Key Copy (hardcode as named constants):

Landing hero: "ê·¸ ë¶„ì´ ì•„ì§ ê³ì— ê³„ì‹¤ ë•Œ."
Landing sub: "ë” ëŠ¦ê¸° ì „ì— ë‚¨ê²¨ë‘ì„¸ìš”."
CTA primary: "ëˆ„êµ°ê°€ì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì‹¶ì–´ìš”"
CTA secondary: "ë‚´ ì´ì•¼ê¸°ë¥¼ ë‚¨ê¸°ê³  ì‹¶ì–´ìš”"
Bottom: "ê·¸ ë¶„ì´ ì•„ì§ ê³ì— ê³„ì‹¤ ë•Œ, ë” ëŠ¦ê¸° ì „ì— ë‚¨ê²¨ë‘ì„¸ìš”."

Interviewee landing: "{requester_name}ë‹˜ì´ {interviewee_name}ì˜ ì´ì•¼ê¸°ë¥¼ ë“£ê³  ì‹¶ì–´í•©ë‹ˆë‹¤."
Consent: "ëŒ€í™” ë‚´ìš©ì´ ê¸°ë¡ë˜ëŠ” ê²ƒì— ë™ì˜í•©ë‹ˆë‹¤."
Consent detail: "ê¸°ë¡ì€ {requester_name}ë‹˜ê³¼ ë³¸ì¸ë§Œ ì—´ëŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

Completion: "ì†Œì¤‘í•œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."
Completion detail: "ì˜¤ëŠ˜ì˜ ì´ì•¼ê¸°ëŠ” ì‹œê°„ì´ ì§€ë‚˜ë„ ì‚¬ë¼ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤."

Link generated: "ì‹¤íƒ€ë˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤."

Privacy notice:
- ë…¹ìŒëœ ìŒì„±ê³¼ ëŒ€í™” ê¸°ë¡ì€ ì‹¤íƒ€ë˜ ì„œë²„ì— ì•ˆì „í•˜ê²Œ ë³´ê´€ë©ë‹ˆë‹¤.
- ê¸°ë¡ì€ ìš”ì²­ìì™€ ì¸í„°ë·°ì´ë§Œ ì—´ëŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ì œ3ìì—ê²Œ ê³µìœ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ì–¸ì œë“  ì‚­ì œë¥¼ ìš”ì²­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- í–¥í›„ ìµëª…í™”ëœ í˜•íƒœë¡œ ì§‘ë‹¨ ê¸°ì–µ ì—°êµ¬ì— í™œìš©ë  ìˆ˜ ìˆìœ¼ë©°, ì´ ê²½ìš° ë³„ë„ ë™ì˜ë¥¼ êµ¬í•©ë‹ˆë‹¤.

Error messages:
- Chat failure: "ì ì‹œ ì—°ê²°ì´ ë¶ˆì•ˆì •í•©ë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”."
- Transcribe failure: "ìŒì„± ì¸ì‹ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ ì£¼ì„¸ìš”."
- Create failure: "ë§í¬ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

Mic button hint: "ê¾¹ ëˆ„ë¥´ê³  ë§ì”€í•˜ì„¸ìš”"
Recording indicator: "ë“£ê³  ìˆìŠµë‹ˆë‹¤..."

## Environment Variables

```
OPENAI_API_KEY=sk-...
NEXT_PUBLIC_BASE_URL=https://iyagi.siltare.app
```

## Context

This project is being built for the Hashed Vibe Labs accelerator application.
Deadline: 2026.02.19 23:59 KST.
Integrating 7 v0.dev mockup UIs into one project and
transplanting backend from existing repo (hahnryu/siltare.app).
